{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7c63e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('come', 1), ('write', 1), ('articles', 1), ('for', 1), ('us', 1), ('and', 1), ('get', 1), ('featured', 1)]\n",
      "[('and', 2), ('come', 1), ('write', 1), ('articles', 1), ('for', 1), ('us', 1), ('get', 1), ('featured', 1), ('learn', 1), ('code', 1)]\n",
      "[('and', 3), ('get', 2), ('come', 1), ('write', 1), ('articles', 1), ('for', 1), ('us', 1), ('featured', 1), ('learn', 1), ('code', 1)]\n",
      "[('and', 4), ('come', 2), ('us', 2), ('get', 2), ('with', 2), ('write', 1), ('articles', 1), ('for', 1), ('featured', 1), ('learn', 1)]\n",
      "[('to', 24), ('you', 18), ('the', 16), ('in', 16), ('for', 15), ('is', 15), ('language', 15), ('c', 14), ('and', 13), ('of', 13)]\n"
     ]
    }
   ],
   "source": [
    "# Python3 program for a word frequency\n",
    "# counter after crawling/scraping a web-page\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import operator\n",
    "from collections import Counter\n",
    "\n",
    "'''Function defining the web-crawler/core\n",
    "spider, which will fetch information from\n",
    "a given website, and push the contents to\n",
    "the second function clean_wordlist()'''\n",
    "\n",
    "\n",
    "def start(url):\n",
    "\n",
    "    # empty list to store the contents of\n",
    "    # the website fetched from our web-crawler\n",
    "    wordlist = []\n",
    "    source_code = requests.get(url).text\n",
    "\n",
    "    # BeautifulSoup object which will\n",
    "    # ping the requested url for data\n",
    "    soup = BeautifulSoup(source_code, 'html.parser')\n",
    "\n",
    "    # Text in given web-page is stored under\n",
    "    # the <div> tags with class <entry-content>\n",
    "    for each_text in soup.findAll('div', {'class': 'text'}):\n",
    "        content = each_text.text\n",
    "        # use split() to break the sentence into\n",
    "        # words and convert them into lowercase\n",
    "        words = content.lower().split()\n",
    "\n",
    "        for each_word in words:\n",
    "            wordlist.append(each_word)\n",
    "        clean_wordlist(wordlist)\n",
    "\n",
    "# Function removes any unwanted symbols\n",
    "\n",
    "\n",
    "def clean_wordlist(wordlist):\n",
    "\n",
    "    clean_list = []\n",
    "    for word in wordlist:\n",
    "        symbols = \"!@#$%^&*()_-+={[}]|\\;:\\\"<>?/., \"\n",
    "        \n",
    "        for i in range(len(symbols)):\n",
    "            word = word.replace(symbols[i], '')\n",
    "\n",
    "        if len(word) > 0:\n",
    "            clean_list.append(word)\n",
    "    create_dictionary(clean_list)\n",
    "        \n",
    "# Creates a dictionary containing each word's\n",
    "# count and top_20 occurring words\n",
    "\n",
    "\n",
    "def create_dictionary(clean_list):\n",
    "    word_count = {}\n",
    "\n",
    "    for word in clean_list:\n",
    "        if word in word_count:\n",
    "            word_count[word] += 1\n",
    "        else:\n",
    "            word_count[word] = 1\n",
    "\n",
    "    ''' To get the count of each word in\n",
    "    the crawled page -->\n",
    "    \n",
    "    # operator.itemgetter() takes one\n",
    "    # parameter either 1(denotes keys)\n",
    "    # or 0 (denotes corresponding values)\n",
    "\n",
    "for key, value in sorted(word_count.items(),\n",
    "key = operator.itemgetter(1)):\n",
    "print (\"% s : % s \" % (key, value))\n",
    "\n",
    "<-- '''\n",
    "    c = Counter(word_count)\n",
    "\n",
    "    # returns the most occurring elements\n",
    "    top = c.most_common(10)\n",
    "    print(top)\n",
    "\n",
    "\n",
    "# Driver code\n",
    "if __name__ == '__main__':\n",
    "    url = \"https://www.geeksforgeeks.org/programming-language-choose/\"\n",
    "    # starts crawling and prints output\n",
    "    start(url)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
